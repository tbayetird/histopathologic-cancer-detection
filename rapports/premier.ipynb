{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic cancer detection : premiers essais \n",
    "\n",
    "L'approche pour les débuts sur la détection histopathologique du cancer était la suivante : commencer petit, et s'améliorer au fur et à mesure. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premiers tests \n",
    "\n",
    "Nous avons donc commencé avec des modèles simples, sur des bases de données simples : \n",
    "- 20 données d'entrainement \n",
    "- 10 données de validation \n",
    "- 10 données de test. \n",
    "\n",
    "Concernant le réseau, il était lui aussi très simple : deux couches denses, avec peu de neurones. \n",
    "Le but d'une telle implémentation n'est pas d'obtenir des résultats valides, mais plutôt de valider le workflow, et donc : \n",
    "- de mettre au point les procédés de récupération des données (mise en forme du jeu de données) \n",
    "- d'implémenter la récupération et le préprocess des données (augmentation, normalisation, mise en place de générateurs)\n",
    "- d'implémenter un réseau de neurone valide pour ces données (inputs et outputs compatibles) \n",
    "- de mettre en place les procédés d'entrainement, de tests, et de suivi des performances.\n",
    "\n",
    "On commence donc avec un tout petit réseau pour le travail de ce workflow : \n",
    "\n",
    "![réseau dense](Pictures\\\\dense_network.PNG)\n",
    "\n",
    "Les résultats obtenus avec ce genre de réseau sur des données aussi peu fournies ne sont pas intéressants ; nous avons donc commencé à utiliser des bases de données plus fournies, sur des réseaux plus adaptés et plus gros : \n",
    " - 800 données en entrainement \n",
    " - 200 données en validation \n",
    " - 1000 données en test \n",
    " \n",
    " Le réseau utilisé est un petit réseau de convolution 2D. Ces réseaux sont particulièrement efficaces pour traiter les problèmes relatifs au traitement d'images. Il est de la forme suivante : \n",
    "![réseau convolutif simple](Pictures\\\\simple_convo_network.PNG)\n",
    " \n",
    "Les résultats obtenus, après entrainement, sont observables sur les graphes suivants : \n",
    "\n",
    "![résultats_simple_convo](Pictures\\\\non_converging_network.PNG)\n",
    "\n",
    "On observe une valeur pratiquement constante pour les données d'entrainement, tandis que les scores de validation sont divergents. Le réseau tel quel n'apprends donc pas. Nous avons avancés plusieurs hypothèses pour expliquer ces résultats : \n",
    "- Les données sont mal régularisées (erreur dans l'augmentation ou la normalisation) \n",
    "- Nous travaillons sur trop peu de données \n",
    "- La taille du batch perturbe l'apprentissage \n",
    "- Le modèle est trop simple pour représenter efficacement les données \n",
    "- les paramètres d'entrainement (learning rate, optimizer, ...) sont mauvais \n",
    "- Les données telles quelles(96x96) ne permettent pas d'extrapoler la présence de cellules cancéreuses en leur centre (32x32). \n",
    "\n",
    "Différentes hypothèses sont rapidement testées (régularisation des données, taille du batch, paramètres d'entrainement, ...) avant de tester la complexification du réseau (plus de données, modèle plus complexe. L'état des tests est alors le suivant : \n",
    "- 8 000 données en entrainement \n",
    "- 2 000 données en validation \n",
    "- 2 000 données en test \n",
    "\n",
    "Le modèle utilisé est toujours un modèle de convolution, mais plus développé que le précédent : \n",
    "\n",
    "![réseau convolutif](Pictures\\\\convo_network.PNG)\n",
    "\n",
    "Les résultats obtenus après entrainement sont observables sur les graphes suivants : \n",
    "\n",
    "![résultats_convo](Pictures\\\\converging_network.PNG)\n",
    "\n",
    "Ce que l'on peut comprendre de ces graphes, c'est : \n",
    "- que ce réseau apprend bien à reconnaitre des cellules cancéreuses dans les images \n",
    "- qu'il y a un léger overfit des données d'entrainement par rapport aux données de tests \n",
    "\n",
    "\n",
    "On obtient dès lors une précision de l'ordre de 0.8 sur notre jeu de données, ce qui est un début correct. Les pistes d'amélioration sont les suivantes : \n",
    "- Un réseau plus gros serait probablement plus performant \n",
    "- Travailler sur un plus gros jeu de données pourrait augmenter la précision finale \n",
    "- Travailler la régularisation (Dropout, Batch normalization, ...) pour éviter l'overfit \n",
    "- Faire varier la learning rate au fur et à mesure de l'entrainement du réseau \n",
    "- Augmenter encore le nombre d'épochs pour l'entrainement du réseau \n",
    "- Télécharger des réseaux pré-entrainés et procéder à du transfert-learning et fine-tuning pour gagner encore de la précision \n",
    "\n",
    "On observera, d'autre part, que certaines limites commencent à intervenir : \n",
    "- Pour Ahmad, l'entrainement du dernier réseau sur un dataset de 10000 données a pris une nuit entière sur sa machine (Macbook Pro). En comparaison, sur une machine équipée d'un GPU (Nvidia Gefore 1050), celà n'a pris que 10 minutes. \n",
    "- L'utilisation de réseaux pré-entrainés demandera leur téléchargement préalable, tâche qui parait ardue au local de l'IRD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
